{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 59284 samples, validate on 14822 samples\n",
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "   32/59284 [..............................] - ETA: 5:12:10 - loss: 0.0263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4be8db095a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m#history_object = model.fit_generator(train_generator, samples_per_epoch=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten , Dense ,Lambda , Conv2D, MaxPooling2D ,Dropout , Cropping2D\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from numba import cuda \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load(samples):\n",
    "    \n",
    "    if True: \n",
    "        num_samples = len(samples)\n",
    "\n",
    "        images = []\n",
    "        measurements = []\n",
    "        Correction = 0.2\n",
    "\n",
    "        #for offset in range(0, num_samples, batch_size):\n",
    "        if True:\n",
    "            for line in samples :\n",
    "                source_path = line[0]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                current_path = 'data/IMG/' + filename\n",
    "                image = cv2.imread(current_path)   \n",
    "                images.append(image)\n",
    "                measurement = float(line[3])\n",
    "                measurements.append(measurement)\n",
    "\n",
    "\n",
    "                image_flipped = np.fliplr(image)\n",
    "                images.append(image_flipped)    \n",
    "                measurement_flipped = (-1) * measurement\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "                source_pathL = line[1]\n",
    "                filenameL = source_pathL.split('/')[-1]\n",
    "                current_pathL = 'data/IMG/' + filenameL\n",
    "                imageL = cv2.imread(current_pathL)   \n",
    "                images.append(imageL)\n",
    "                measurements.append(measurement + Correction)\n",
    "\n",
    "                image_flippedL = np.fliplr(imageL)\n",
    "                images.append(image_flippedL)    \n",
    "                measurement_flippedL = ((-1) * (measurement + Correction))\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "\n",
    "                source_pathR = line[2]\n",
    "                filenameR = source_pathR.split('/')[-1]\n",
    "                current_pathR = 'data/IMG/' + filenameR\n",
    "                imageR = cv2.imread(current_pathR)   \n",
    "                images.append(imageR)\n",
    "                measurements.append(measurement - Correction)\n",
    "\n",
    "                image_flippedR = np.fliplr(imageR)\n",
    "                images.append(image_flippedR)    \n",
    "                measurement_flippedR = ((-1) * (measurement - Correction))\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            \n",
    "            return X_train , y_train\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "\n",
    "X_train , y_train =  load(lines)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)) ,  input_shape = (160,320,3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255) - 0.5 ))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(36, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(48, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "model.add(Dense(50))\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse' , optimizer = 'adam')\n",
    "\n",
    "history_object = model.fit(X_train,y_train,validation_split = 0.2 ,shuffle = True , epochs = 3)\n",
    "\n",
    "#history_object = model.fit_generator(train_generator, samples_per_epoch= \n",
    "#            len(X_train), validation_data=validation_generator, \n",
    "#            nb_val_samples=len(y_train), nb_epoch=3)\n",
    "\n",
    "#history_object = model.fit_generator(train_generator, steps_per_epoch= (len(train)*6)//BS,\n",
    "#validation_data=validation_generator, validation_steps=(len(valid)*6)//BS, epochs=3, verbose = 1,workers=1)\n",
    "\n",
    "#H = model.fit_generator(datagen.flow(X_train, y_train, batch_size=BS),\n",
    "#    steps_per_epoch=len(X_train) // BS,\n",
    "#    epochs=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#clear memory\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear memory\n",
    "from numba import cuda \n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0841ebc5ced2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aug' is not defined"
     ]
    }
   ],
   "source": [
    "aug.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmatronics/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "/home/ahmatronics/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4640ef126712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    163\u001b[0m history_object = model.fit_generator(train_generator, steps_per_epoch= (len(train)*6)//BS,\n\u001b[1;32m    164\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#pickle_safe=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                                      , max_queue_size=10,use_multiprocessing=True,workers=6)\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten , Dense ,Lambda , Conv2D, MaxPooling2D ,Dropout , Cropping2D\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from numba import cuda \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    \n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        num_samples = len(samples)\n",
    "\n",
    "        images = []\n",
    "        measurements = []\n",
    "        Correction = 0.2\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "\n",
    "            for line in samples[offset:(offset+batch_size)] :\n",
    "                source_path = line[0]\n",
    "                filename = source_path.split('/')[-1]\n",
    "                current_path = 'data/IMG/' + filename\n",
    "                image = cv2.imread(current_path)   \n",
    "                images.append(image)\n",
    "                measurement = float(line[3])\n",
    "                measurements.append(measurement)\n",
    "\n",
    "\n",
    "                image_flipped = np.fliplr(image)\n",
    "                images.append(image_flipped)    \n",
    "                measurement_flipped = (-1) * measurement\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "                source_pathL = line[1]\n",
    "                filenameL = source_pathL.split('/')[-1]\n",
    "                current_pathL = 'data/IMG/' + filenameL\n",
    "                imageL = cv2.imread(current_pathL)   \n",
    "                images.append(imageL)\n",
    "                measurements.append(measurement + Correction)\n",
    "\n",
    "                image_flippedL = np.fliplr(imageL)\n",
    "                images.append(image_flippedL)    \n",
    "                measurement_flippedL = ((-1) * (measurement + Correction))\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "\n",
    "                source_pathR = line[2]\n",
    "                filenameR = source_pathR.split('/')[-1]\n",
    "                current_pathR = 'data/IMG/' + filenameR\n",
    "                imageR = cv2.imread(current_pathR)   \n",
    "                images.append(imageR)\n",
    "                measurements.append(measurement - Correction)\n",
    "\n",
    "                image_flippedR = np.fliplr(imageR)\n",
    "                images.append(image_flippedR)    \n",
    "                measurement_flippedR = ((-1) * (measurement - Correction))\n",
    "                measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            X_train , y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "            yield (X_train , y_train) \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "\n",
    "samples_num = len(lines)\n",
    "ratio = 0.8\n",
    "BS = 8\n",
    "\n",
    "\n",
    "train = lines[0:int(ratio * samples_num)]\n",
    "\n",
    "valid = lines[int(ratio * samples_num):]\n",
    "\n",
    "\n",
    "train_generator =  generator(train, batch_size=BS)\n",
    "\n",
    "validation_generator = generator(valid, batch_size=BS)\n",
    "\n",
    "\n",
    "#datagen =ImageDataGenerator(validation_split = 0.2)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "#datagen.fit(X_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)) ,  input_shape = (160,320,3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255) - 0.5 ))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(36, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(48, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(100))\n",
    "\n",
    "#model.add(Dense(50))\n",
    "\n",
    "#model.add(Dense(10))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse' , optimizer = 'adam')\n",
    "\n",
    "#history_object = model.fit(X_train,y_train,validation_split = 0.2 ,shuffle = True , epochs = 3)\n",
    "\n",
    "#history_object = model.fit_generator(train_generator, samples_per_epoch= \n",
    "#            len(X_train), validation_data=validation_generator, \n",
    "#            nb_val_samples=len(y_train), nb_epoch=3)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= (len(train)*6)//BS,\n",
    "validation_data=validation_generator, validation_steps=(len(valid)*6)//BS, epochs=3,verbose = 3 #pickle_safe=True\n",
    "                                     , max_queue_size=10,use_multiprocessing=True,workers=6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#max_queue_size=10,,,\n",
    "#H = model.fit_generator(datagen.flow(X_train, y_train, batch_size=BS),\n",
    "#    steps_per_epoch=len(X_train) // BS,\n",
    "#    epochs=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#clear memory\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, files, batch_size=2, dim=(160, 160), n_channels=3,\n",
    "                 n_classes=2, shuffle=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.files = files\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.len = int(np.floor(len(self.files)/ self.batch_size))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        print (\"Number of batches per epoch\")\n",
    "        print(self.len)\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        files_temp = [self.files[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(files_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files)*6)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, files_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        samples = files_temp\n",
    "        num_samples = len(samples)\n",
    "        images = []\n",
    "        measurements = []\n",
    "        Correction = 0.2\n",
    "        \n",
    "        for line in samples:\n",
    "            source_path = line[0]\n",
    "            filename = source_path.split('/')[-1]\n",
    "            current_path = 'data/IMG/' + filename\n",
    "            image = cv2.imread(current_path)   \n",
    "            images.append(image)\n",
    "            measurement = float(line[3])\n",
    "            measurements.append(measurement)\n",
    "\n",
    "\n",
    "            image_flipped = np.fliplr(image)\n",
    "            images.append(image_flipped)    \n",
    "            measurement_flipped = (-1) * measurement\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            source_pathL = line[1]\n",
    "            filenameL = source_pathL.split('/')[-1]\n",
    "            current_pathL = 'data/IMG/' + filenameL\n",
    "            imageL = cv2.imread(current_pathL)   \n",
    "            images.append(imageL)\n",
    "            measurements.append(measurement + Correction)\n",
    "\n",
    "            image_flippedL = np.fliplr(imageL)\n",
    "            images.append(image_flippedL)    \n",
    "            measurement_flippedL = ((-1) * (measurement + Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "\n",
    "            source_pathR = line[2]\n",
    "            filenameR = source_pathR.split('/')[-1]\n",
    "            current_pathR = 'data/IMG/' + filenameR\n",
    "            imageR = cv2.imread(current_pathR)   \n",
    "            images.append(imageR)\n",
    "            measurements.append(measurement - Correction)\n",
    "\n",
    "            image_flippedR = np.fliplr(imageR)\n",
    "            images.append(image_flippedR)    \n",
    "            measurement_flippedR = ((-1) * (measurement - Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            X_train , y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "            self.len = int(np.floor(len(images)))\n",
    "            \n",
    "        return X, y #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "params = {'dim': (160, 160),\n",
    "              'batch_size': 2,\n",
    "              'n_classes': 2,\n",
    "              'n_channels': 3,\n",
    "              'shuffle': True}\n",
    "\n",
    "\n",
    "gen_train = DataGenerator(files, **params)\n",
    "model.fit_generator(gen_train, steps_per_epoch=ceil(num_samples_train)/batch_size, validation_data=None,\n",
    "        epochs = 1,  verbose=1,\n",
    "    callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Number of batches per epoch\n",
      "154\n",
      "\n",
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Number of batches per epoch\n",
      "154\n",
      "\n",
      "Number of batches per epoch\n",
      "1389\n",
      "Epoch 1/3\n",
      "\n",
      "1388/1389 [============================>.] - ETA: 0s - loss: 0.0609Number of batches per epoch\n",
      "1389\n",
      "\n",
      "Number of batches per epoch\n",
      "154\n",
      "\n",
      "1389/1389 [==============================] - 241s 173ms/step - loss: 0.0609 - val_loss: 0.0139\n",
      "Epoch 2/3\n",
      "1388/1389 [============================>.] - ETA: 0s - loss: 0.0276Number of batches per epoch\n",
      "1389\n",
      "\n",
      "Number of batches per epoch\n",
      "154\n",
      "\n",
      "1389/1389 [==============================] - 239s 172ms/step - loss: 0.0276 - val_loss: 0.0423\n",
      "Epoch 3/3\n",
      "1388/1389 [============================>.] - ETA: 0s - loss: 0.0276Number of batches per epoch\n",
      "1389\n",
      "\n",
      "Number of batches per epoch\n",
      "154\n",
      "\n",
      "1389/1389 [==============================] - 239s 172ms/step - loss: 0.0276 - val_loss: 0.0537\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten , Dense ,Lambda , Conv2D, MaxPooling2D ,Dropout , Cropping2D\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from numba import cuda \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import sklearn\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, files, batch_size=2, dim=(160, 160), n_channels=3,shuffle=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.files = files\n",
    "        self.batch_size = int(batch_size / 6) # because each line of data generates 6 photos and an angle\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.len = int(np.floor(len(self.files) / self.batch_size)) \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        print()\n",
    "        print (\"Number of batches per epoch\" , self.len)\n",
    "        print()\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        files_temp = [self.files[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(files_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, files_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        samples = files_temp\n",
    "        num_samples = len(samples)\n",
    "        images = []\n",
    "        measurements = []\n",
    "        Correction = 0.2\n",
    "        \n",
    "        for line in samples:\n",
    "            source_path = line[0]\n",
    "            filename = source_path.split('/')[-1]\n",
    "            current_path = 'data/IMG/' + filename\n",
    "            image = cv2.imread(current_path)   \n",
    "            images.append(image)\n",
    "            measurement = float(line[3])\n",
    "            measurements.append(measurement)\n",
    "\n",
    "            \n",
    "            \n",
    "            image_flipped = np.fliplr(image)\n",
    "            images.append(image_flipped)    \n",
    "            measurement_flipped = (-1) * measurement\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            source_pathL = line[1]\n",
    "            filenameL = source_pathL.split('/')[-1]\n",
    "            current_pathL = 'data/IMG/' + filenameL\n",
    "            imageL = cv2.imread(current_pathL)   \n",
    "            images.append(imageL)\n",
    "            measurements.append(measurement + Correction)\n",
    "\n",
    "            image_flippedL = np.fliplr(imageL)\n",
    "            images.append(image_flippedL)    \n",
    "            measurement_flippedL = ((-1) * (measurement + Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "\n",
    "            source_pathR = line[2]\n",
    "            filenameR = source_pathR.split('/')[-1]\n",
    "            current_pathR = 'data/IMG/' + filenameR\n",
    "            imageR = cv2.imread(current_pathR)   \n",
    "            images.append(imageR)\n",
    "            measurements.append(measurement - Correction)\n",
    "\n",
    "            image_flippedR = np.fliplr(imageR)\n",
    "            images.append(image_flippedR)    \n",
    "            measurement_flippedR = ((-1) * (measurement - Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        images = np.array(images)\n",
    "        measurements = np.array(measurements)\n",
    "        X, Y = sklearn.utils.shuffle(images, measurements)\n",
    "        return  X, Y  #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "\n",
    "samples_num = len(lines)\n",
    "ratio = 0.9\n",
    "\n",
    "\n",
    "train = lines[0:int(ratio * samples_num)]\n",
    "\n",
    "valid = lines[int(ratio * samples_num):]\n",
    "\n",
    "params = {'dim': (160,320),\n",
    "              'batch_size': 48,\n",
    "              'n_channels': 3,\n",
    "              'shuffle': True}\n",
    "\n",
    "            \n",
    "train_generator =  DataGenerator(train,**params)\n",
    "\n",
    "validation_generator = DataGenerator(valid, **params)\n",
    "\n",
    "\n",
    "#datagen =ImageDataGenerator(validation_split = 0.2)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "#datagen.fit(X_train)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)) ,  input_shape = (160,320,3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1 ))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(36, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(48, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "model.add(Dense(50))\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse' , optimizer = 'adam')\n",
    "\n",
    "#history_object = model.fit(X_train,y_train,validation_split = 0.2 ,shuffle = True , epochs = 3)\n",
    "\n",
    "#history_object = model.fit_generator(train_generator, samples_per_epoch= \n",
    "#            len(X_train), validation_data=validation_generator, \n",
    "#            nb_val_samples=len(y_train), nb_epoch=3)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= train_generator.len ,\n",
    "validation_data=validation_generator, validation_steps=validation_generator.len, epochs=3,verbose = 1) #pickle_safe=True\n",
    "                                     #, max_queue_size=10,use_multiprocessing=True,workers=10)\n",
    "\n",
    "\n",
    "#history_object = model.fit_generator(train_generator, steps_per_epoch=train_generator.len, validation_data=None,\n",
    "#        epochs = 1,  verbose=1,\n",
    "#    callbacks = [TensorBoard])\n",
    "\n",
    "#max_queue_size=10,,,\n",
    "#H = model.fit_generator(datagen.flow(X_train, y_train, batch_size=BS),\n",
    "#    steps_per_epoch=len(X_train) // BS,\n",
    "#    epochs=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#clear memory\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "Number of batches per epoch 21\n",
      "\n",
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5d896a664d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    213\u001b[0m history_object = model.fit_generator(train_generator, steps_per_epoch= train_generator.len ,\n\u001b[1;32m    214\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                     ,max_queue_size=10) \n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                     **self._function_kwargs)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3005\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3006\u001b[0;31m         \u001b[0mv1_variable_initialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[1;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mv1_variable_initialization\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mv1_variable_initialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;34m'`get_session` is not available when '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             'TensorFlow is executing eagerly.')\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_keras_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten , Dense ,Lambda , Conv2D, MaxPooling2D ,Dropout , Cropping2D\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from numba import cuda \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import sklearn\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, files, batch_size=2, dim=(160, 160), n_channels=3,shuffle=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.files = files\n",
    "        self.batch_size = int(batch_size / 2) # because each line of data generates 2 photos and an angle\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.len = int(np.floor(len(self.files) / self.batch_size)) \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        print()\n",
    "        print (\"Number of batches per epoch\" , self.len)\n",
    "        print()\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        files_temp = [self.files[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(files_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, files_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        samples = files_temp\n",
    "        num_samples = len(samples)\n",
    "        images = []\n",
    "        measurements = []\n",
    "        Correction = 0.2\n",
    "        \n",
    "        for line in samples:\n",
    "            source_path = line[0]\n",
    "            filename = source_path.split('/')[-1]\n",
    "            current_path = 'data/IMG/' + filename\n",
    "            image = cv2.imread(current_path)   \n",
    "            images.append(image)\n",
    "            measurement = float(line[3])\n",
    "            measurement *= 100  #############################################################\n",
    "            measurements.append(measurement)\n",
    "\n",
    "            image_flipped = np.fliplr(image)\n",
    "            images.append(image_flipped)    \n",
    "            measurement_flipped = (-1) * measurement\n",
    "            measurements.append(measurement_flipped)            \n",
    "\n",
    "            source_pathL = line[1]\n",
    "            filenameL = source_pathL.split('/')[-1]\n",
    "            current_pathL = 'data/IMG/' + filenameL\n",
    "            imageL = cv2.imread(current_pathL)   \n",
    "            images.append(imageL)\n",
    "            measurements.append(measurement + Correction)\n",
    "\n",
    "            image_flippedL = np.fliplr(imageL)\n",
    "            images.append(image_flippedL)    \n",
    "            measurement_flippedL = ((-1) * (measurement + Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "\n",
    "            source_pathR = line[2]\n",
    "            filenameR = source_pathR.split('/')[-1]\n",
    "            current_pathR = 'data/IMG/' + filenameR\n",
    "            imageR = cv2.imread(current_pathR)   \n",
    "            images.append(imageR)\n",
    "            measurements.append(measurement - Correction)\n",
    "\n",
    "            image_flippedR = np.fliplr(imageR)\n",
    "            images.append(image_flippedR)    \n",
    "            measurement_flippedR = ((-1) * (measurement - Correction))\n",
    "            measurements.append(measurement_flipped)\n",
    "\n",
    "\n",
    "        images = np.array(images)\n",
    "        measurements = np.array(measurements)\n",
    "        X, Y = sklearn.utils.shuffle(images, measurements)\n",
    "        return  X, Y  #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "   \n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "\n",
    "samples_num = len(lines)\n",
    "ratio = 0.8\n",
    "\n",
    "\n",
    "lines = sklearn.utils.shuffle(lines)\n",
    "\n",
    "train = lines[0:int(ratio * samples_num)]\n",
    "\n",
    "valid = lines[int(ratio * samples_num):]\n",
    "\n",
    "params = {'dim': (160,320),\n",
    "              'batch_size': 32,\n",
    "              'n_channels': 3,\n",
    "              'shuffle': True}\n",
    "\n",
    "            \n",
    "train_generator =  DataGenerator(train,**params)\n",
    "\n",
    "validation_generator = DataGenerator(valid, **params)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)) ,  input_shape = (160,320,3)))\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1. ))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(36, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "model.add(Conv2D(48, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
    "\n",
    "#MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(500))\n",
    "\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(50))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mse' , optimizer = 'adam')\n",
    "\n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= train_generator.len ,\n",
    "validation_data=validation_generator, validation_steps=validation_generator.len, epochs=6,verbose = 1 , workers=16\n",
    "                                    ,max_queue_size=10) \n",
    "\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Model Saved')\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#clear memory\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "print('Cuda reset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ahmatronics/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Number of batches per epoch 56\n",
      "\n",
      "\n",
      "\n",
      "Number of batches per epoch 226\n",
      "\n",
      "Epoch 1/6Number of batches per epoch\n",
      " 56\n",
      "\n",
      "  1/226 [..............................] - ETA: 14:07 - loss: 424.4799"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[998784,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/dense_1/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95dfbb058371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    169\u001b[0m history_object = model.fit_generator(train_generator, steps_per_epoch= train_generator.len ,\n\u001b[1;32m    170\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                                     ,max_queue_size=10) \n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[998784,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/dense_1/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
